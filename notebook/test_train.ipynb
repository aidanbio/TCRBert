{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-11-22T08:26:40.582780092Z",
     "start_time": "2023-11-22T08:26:40.540452215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-22 17:26:40 [INFO]: Loaded exp_conf: {'title': 'testexp', 'description': 'testexp', 'paper': 'ASAP', 'model_config': '../config/bert-base/', 'outdir': '../output/testexp', 'train': {'pretrained_model': {'type': 'tape', 'location': '../config/bert-base/'}, 'data_parallel': True, 'backup': 'train.bak.{date}.tar.gz', 'rounds': [{'data': 'dash_vdjdb_mcpas', 'test_size': 0.2, 'batch_size': 256, 'n_epochs': 2, 'n_workers': 12, 'metrics': ['accuracy'], 'optimizer': {'type': 'adamw', 'lr': 0.0001}, 'train_bert_encoders': [-10, None], 'early_stopper': {'monitor': 'accuracy', 'patience': 1}, 'model_checkpoint': {'chk': 'train.{round}.model_{epoch}.chk', 'monitor': 'accuracy', 'save_best_only': True, 'period': 1}, 'result': 'train.{round}.result.json'}, {'data': 'dash_vdjdb_mcpas', 'test_size': 0.2, 'batch_size': 256, 'n_epochs': 2, 'n_workers': 12, 'metrics': ['accuracy'], 'optimizer': {'type': 'adamw', 'lr': 0.0001}, 'train_bert_encoders': [-6, None], 'early_stopper': {'monitor': 'accuracy', 'patience': 1}, 'model_checkpoint': {'chk': 'train.{round}.model_{epoch}.chk', 'monitor': 'accuracy', 'save_best_only': True, 'period': 1}, 'result': 'train.{round}.result.json'}]}, 'eval': {'data_parallel': False, 'batch_size': 128, 'n_workers': 12, 'metrics': ['accuracy', 'f1', 'roc_auc'], 'output_attentions': False, 'tests': [{'data': 'shomuradova', 'result': 'eval.shomuradova.result.json'}, {'data': 'immunecode', 'result': 'eval.immunecode.result.json'}]}}\n",
      "2023-11-22 17:26:40 [INFO]: Loaded exp_conf: {'title': 'testexp', 'description': 'testexp', 'paper': 'ASAP', 'model_config': '../config/bert-base/', 'outdir': '../output/testexp', 'train': {'pretrained_model': {'type': 'tape', 'location': '../config/bert-base/'}, 'data_parallel': True, 'backup': 'train.bak.{date}.tar.gz', 'rounds': [{'data': 'dash_vdjdb_mcpas', 'test_size': 0.2, 'batch_size': 256, 'n_epochs': 2, 'n_workers': 12, 'metrics': ['accuracy'], 'optimizer': {'type': 'adamw', 'lr': 0.0001}, 'train_bert_encoders': [-10, None], 'early_stopper': {'monitor': 'accuracy', 'patience': 1}, 'model_checkpoint': {'chk': 'train.{round}.model_{epoch}.chk', 'monitor': 'accuracy', 'save_best_only': True, 'period': 1}, 'result': 'train.{round}.result.json'}, {'data': 'dash_vdjdb_mcpas', 'test_size': 0.2, 'batch_size': 256, 'n_epochs': 2, 'n_workers': 12, 'metrics': ['accuracy'], 'optimizer': {'type': 'adamw', 'lr': 0.0001}, 'train_bert_encoders': [-6, None], 'early_stopper': {'monitor': 'accuracy', 'patience': 1}, 'model_checkpoint': {'chk': 'train.{round}.model_{epoch}.chk', 'monitor': 'accuracy', 'save_best_only': True, 'period': 1}, 'result': 'train.{round}.result.json'}]}, 'eval': {'data_parallel': False, 'batch_size': 128, 'n_workers': 12, 'metrics': ['accuracy', 'f1', 'roc_auc'], 'output_attentions': False, 'tests': [{'data': 'shomuradova', 'result': 'eval.shomuradova.result.json'}, {'data': 'immunecode', 'result': 'eval.immunecode.result.json'}]}}\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'title': 'testexp',\n 'description': 'testexp',\n 'paper': 'ASAP',\n 'model_config': '../config/bert-base/',\n 'outdir': '../output/testexp',\n 'train': {'pretrained_model': {'type': 'tape',\n   'location': '../config/bert-base/'},\n  'data_parallel': True,\n  'backup': 'train.bak.{date}.tar.gz',\n  'rounds': [{'data': 'dash_vdjdb_mcpas',\n    'test_size': 0.2,\n    'batch_size': 256,\n    'n_epochs': 2,\n    'n_workers': 12,\n    'metrics': ['accuracy'],\n    'optimizer': {'type': 'adamw', 'lr': 0.0001},\n    'train_bert_encoders': [-10, None],\n    'early_stopper': {'monitor': 'accuracy', 'patience': 1},\n    'model_checkpoint': {'chk': 'train.{round}.model_{epoch}.chk',\n     'monitor': 'accuracy',\n     'save_best_only': True,\n     'period': 1},\n    'result': 'train.{round}.result.json'},\n   {'data': 'dash_vdjdb_mcpas',\n    'test_size': 0.2,\n    'batch_size': 256,\n    'n_epochs': 2,\n    'n_workers': 12,\n    'metrics': ['accuracy'],\n    'optimizer': {'type': 'adamw', 'lr': 0.0001},\n    'train_bert_encoders': [-6, None],\n    'early_stopper': {'monitor': 'accuracy', 'patience': 1},\n    'model_checkpoint': {'chk': 'train.{round}.model_{epoch}.chk',\n     'monitor': 'accuracy',\n     'save_best_only': True,\n     'period': 1},\n    'result': 'train.{round}.result.json'}]},\n 'eval': {'data_parallel': False,\n  'batch_size': 128,\n  'n_workers': 12,\n  'metrics': ['accuracy', 'f1', 'roc_auc'],\n  'output_attentions': False,\n  'tests': [{'data': 'shomuradova', 'result': 'eval.shomuradova.result.json'},\n   {'data': 'immunecode', 'result': 'eval.immunecode.result.json'}]}}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import logging\n",
    "import logging.config\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from enum import auto\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.display import display\n",
    "\n",
    "rootdir = '/home/hym/trunk/TCRBert'\n",
    "workdir = '%s/notebook' % rootdir\n",
    "datadir = '%s/data' % rootdir\n",
    "srcdir = '%s/tcrbert' % rootdir\n",
    "outdir = '%s/output' % rootdir\n",
    "\n",
    "os.chdir(workdir)\n",
    "\n",
    "sys.path.append(rootdir)\n",
    "sys.path.append(srcdir)\n",
    "\n",
    "from tcrbert.exp import Experiment\n",
    "from tcrbert.predlistener import PredResultRecoder\n",
    "\n",
    "\n",
    "# Display\n",
    "pd.set_option('display.max.rows', 2000)\n",
    "pd.set_option('display.max.columns', 2000)\n",
    "\n",
    "# Logger\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.config.fileConfig('../config/logging.conf')\n",
    "logger = logging.getLogger('tcrbert')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Target experiment\n",
    "exp_key = 'testexp'\n",
    "Experiment.load_exp_conf('testexp', reload=True)\n",
    "experiment = Experiment.from_key(exp_key)\n",
    "\n",
    "exp_conf = experiment.exp_conf\n",
    "\n",
    "display(exp_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     24
    ],
    "ExecuteTime": {
     "end_time": "2023-11-22T08:40:46.780064149Z",
     "start_time": "2023-11-22T08:35:14.919325917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-22 17:35:14 [INFO]: shomuradova dataset was loaded from ../output/shomuradova.data.csv, df.shape: (610, 9)\n",
      "2023-11-22 17:35:14 [INFO]: ======================\n",
      "2023-11-22 17:35:14 [INFO]: Begin train at 2023-11-22 17:35:14.935758\n",
      "2023-11-22 17:35:14 [INFO]: Loading the TAPE pretrained model from ../config/bert-base/\n",
      "2023-11-22 17:35:15 [INFO]: Using DataParallel model with 2 GPUs\n",
      "2023-11-22 17:35:15 [INFO]: Start 2 train rounds of testexp at 2023-11-22 17:35:14.935758\n",
      "2023-11-22 17:35:15 [INFO]: train_conf: {'pretrained_model': {'type': 'tape', 'location': '../config/bert-base/'}, 'data_parallel': True, 'backup': 'train.bak.{date}.tar.gz', 'rounds': [{'data': 'dash_vdjdb_mcpas', 'test_size': 0.2, 'batch_size': 256, 'n_epochs': 2, 'n_workers': 12, 'metrics': ['accuracy'], 'optimizer': {'type': 'adamw', 'lr': 0.0001}, 'train_bert_encoders': [-10, None], 'early_stopper': {'monitor': 'accuracy', 'patience': 1}, 'model_checkpoint': {'chk': 'train.{round}.model_{epoch}.chk', 'monitor': 'accuracy', 'save_best_only': True, 'period': 1}, 'result': 'train.{round}.result.json'}, {'data': 'dash_vdjdb_mcpas', 'test_size': 0.2, 'batch_size': 256, 'n_epochs': 2, 'n_workers': 12, 'metrics': ['accuracy'], 'optimizer': {'type': 'adamw', 'lr': 0.0001}, 'train_bert_encoders': [-6, None], 'early_stopper': {'monitor': 'accuracy', 'patience': 1}, 'model_checkpoint': {'chk': 'train.{round}.model_{epoch}.chk', 'monitor': 'accuracy', 'save_best_only': True, 'period': 1}, 'result': 'train.{round}.result.json'}]}\n",
      "2023-11-22 17:35:15 [INFO]: Start 0 train round using data: dash_vdjdb_mcpas, round_conf: {'data': 'dash_vdjdb_mcpas', 'test_size': 0.2, 'batch_size': 256, 'n_epochs': 2, 'n_workers': 12, 'metrics': ['accuracy'], 'optimizer': {'type': 'adamw', 'lr': 0.0001}, 'train_bert_encoders': [-10, None], 'early_stopper': {'monitor': 'accuracy', 'patience': 1}, 'model_checkpoint': {'chk': 'train.{round}.model_{epoch}.chk', 'monitor': 'accuracy', 'save_best_only': True, 'period': 1}, 'result': 'train.{round}.result.json'}\n",
      "2023-11-22 17:35:16 [INFO]: dash_vdjdb_mcpas dataset was loaded from ../output/dash_vdjdb_mcpas.data.csv, df.shape: (25138, 10)\n",
      "2023-11-22 17:35:16 [INFO]: Start to exclude eval data from train data, df.shape: (25138, 10), target_cols: ['index']\n",
      "2023-11-22 17:35:16 [INFO]: shomuradova dataset was loaded from ../output/shomuradova.data.csv, df.shape: (610, 9)\n",
      "2023-11-22 17:35:16 [INFO]: Excluding shomuradova eval data by index from train data\n",
      "2023-11-22 17:35:16 [INFO]: Current train data.shape: (25138, 10)\n",
      "2023-11-22 17:35:16 [INFO]: immunecode dataset was loaded from ../output/immunecode.data.csv, df.shape: (742, 9)\n",
      "2023-11-22 17:35:16 [INFO]: Excluding immunecode eval data by index from train data\n",
      "2023-11-22 17:35:16 [INFO]: Current train data.shape: (25138, 10)\n",
      "2023-11-22 17:35:16 [INFO]: Final train data.shape: (25138, 10)\n",
      "2023-11-22 17:35:16 [INFO]: The bert encoders to be trained: [-10, None]\n",
      "2023-11-22 17:35:16 [INFO]: ======================\n",
      "2023-11-22 17:35:16 [INFO]: Begin training...\n",
      "2023-11-22 17:35:16 [INFO]: use_cuda, device: True, cuda:0\n",
      "2023-11-22 17:35:16 [INFO]: train.n_data: 20110, test.n_data: 5028\n",
      "2023-11-22 17:35:16 [INFO]: optimizer: AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "2023-11-22 17:35:16 [INFO]: evaluator: <tcrbert.model.BertTCREpitopeModel.PredictionEvaluator object at 0x7ff2d2bca460>\n",
      "2023-11-22 17:35:16 [INFO]: n_epochs: 2\n",
      "2023-11-22 17:35:16 [INFO]: train.batch_size: 256\n",
      "2023-11-22 17:35:16 [INFO]: test.batch_size: 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training in epoch 0/2: 100%|██████████| 79/79 [00:59<00:00,  1.33batch/s]\n",
      "Validating in epoch 0/2: 100%|██████████| 20/20 [00:11<00:00,  1.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-22 17:36:27 [INFO]: [EvalScoreRecoder]: In epoch 0/2, loss train score: 0.6785940407197687, val score: 0.6479369670152664\n",
      "2023-11-22 17:36:27 [INFO]: [EvalScoreRecoder]: In epoch 0/2, accuracy train score: 0.5667649090747013, val score: 0.6095988948170732\n",
      "2023-11-22 17:36:27 [INFO]: [EarlyStopper]: In epoch 0/2, accuracy score: 0.6095988948170732, best accuracy score: -inf;update best score to 0.6095988948170732\n",
      "2023-11-22 17:36:27 [INFO]: [ModelCheckpoint]: Checkpoint at epoch 0: accuracy improved from -inf to 0.6095988948170732, saving model to ../output/testexp/train.0.model_0.chk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training in epoch 1/2: 100%|██████████| 79/79 [00:59<00:00,  1.34batch/s]\n",
      "Validating in epoch 1/2: 100%|██████████| 20/20 [00:11<00:00,  1.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-22 17:37:37 [INFO]: [EvalScoreRecoder]: In epoch 1/2, loss train score: 0.588107004195829, val score: 0.5902026206254959\n",
      "2023-11-22 17:37:37 [INFO]: [EvalScoreRecoder]: In epoch 1/2, accuracy train score: 0.6654024224460688, val score: 0.6545826981707317\n",
      "2023-11-22 17:37:37 [INFO]: [EarlyStopper]: In epoch 1/2, accuracy score: 0.6545826981707317, best accuracy score: 0.6095988948170732;update best score to 0.6545826981707317\n",
      "2023-11-22 17:37:37 [INFO]: [ModelCheckpoint]: Checkpoint at epoch 1: accuracy improved from 0.6095988948170732 to 0.6545826981707317, saving model to ../output/testexp/train.0.model_1.chk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-22 17:37:38 [INFO]: [EvalScoreRecoder]: loss train socres: [0.6785940407197687, 0.588107004195829], val scores: [0.6479369670152664, 0.5902026206254959]\n",
      "2023-11-22 17:37:38 [INFO]: [EvalScoreRecoder]: accuracy train socres: [0.5667649090747013, 0.6654024224460688], val scores: [0.6095988948170732, 0.6545826981707317]\n",
      "2023-11-22 17:37:38 [INFO]: End training...\n",
      "2023-11-22 17:37:38 [INFO]: ======================\n",
      "2023-11-22 17:37:38 [INFO]: 0 train round result: {'metrics': ['accuracy'], 'train.score': OrderedDict([('loss', [0.6785940407197687, 0.588107004195829]), ('accuracy', [0.5667649090747013, 0.6654024224460688])]), 'val.score': OrderedDict([('loss', [0.6479369670152664, 0.5902026206254959]), ('accuracy', [0.6095988948170732, 0.6545826981707317])]), 'n_epochs': 2, 'stopped_epoch': 1, 'monitor': 'accuracy', 'best_epoch': 1, 'best_score': 0.6545826981707317, 'best_chk': '../output/testexp/train.0.model_1.chk'}, writing to ../output/testexp/train.0.result.json\n",
      "2023-11-22 17:37:38 [INFO]: End of 0 train round.\n",
      "2023-11-22 17:37:38 [INFO]: Setting model states with the best checkpoint ../output/testexp/train.0.model_1.chk\n",
      "2023-11-22 17:37:38 [INFO]: Loaded best model states from ../output/testexp/train.0.model_1.chk\n",
      "2023-11-22 17:37:38 [INFO]: Start 1 train round using data: dash_vdjdb_mcpas, round_conf: {'data': 'dash_vdjdb_mcpas', 'test_size': 0.2, 'batch_size': 256, 'n_epochs': 2, 'n_workers': 12, 'metrics': ['accuracy'], 'optimizer': {'type': 'adamw', 'lr': 0.0001}, 'train_bert_encoders': [-6, None], 'early_stopper': {'monitor': 'accuracy', 'patience': 1}, 'model_checkpoint': {'chk': 'train.{round}.model_{epoch}.chk', 'monitor': 'accuracy', 'save_best_only': True, 'period': 1}, 'result': 'train.{round}.result.json'}\n",
      "2023-11-22 17:37:38 [INFO]: dash_vdjdb_mcpas dataset was loaded from ../output/dash_vdjdb_mcpas.data.csv, df.shape: (25138, 10)\n",
      "2023-11-22 17:37:38 [INFO]: Start to exclude eval data from train data, df.shape: (25138, 10), target_cols: ['index']\n",
      "2023-11-22 17:37:38 [INFO]: shomuradova dataset was loaded from ../output/shomuradova.data.csv, df.shape: (610, 9)\n",
      "2023-11-22 17:37:38 [INFO]: Excluding shomuradova eval data by index from train data\n",
      "2023-11-22 17:37:39 [INFO]: Current train data.shape: (25138, 10)\n",
      "2023-11-22 17:37:39 [INFO]: immunecode dataset was loaded from ../output/immunecode.data.csv, df.shape: (742, 9)\n",
      "2023-11-22 17:37:39 [INFO]: Excluding immunecode eval data by index from train data\n",
      "2023-11-22 17:37:39 [INFO]: Current train data.shape: (25138, 10)\n",
      "2023-11-22 17:37:39 [INFO]: Final train data.shape: (25138, 10)\n",
      "2023-11-22 17:37:39 [INFO]: The bert encoders to be trained: [-6, None]\n",
      "2023-11-22 17:37:39 [INFO]: ======================\n",
      "2023-11-22 17:37:39 [INFO]: Begin training...\n",
      "2023-11-22 17:37:39 [INFO]: use_cuda, device: True, cuda:0\n",
      "2023-11-22 17:37:39 [INFO]: train.n_data: 20110, test.n_data: 5028\n",
      "2023-11-22 17:37:39 [INFO]: optimizer: AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "2023-11-22 17:37:39 [INFO]: evaluator: <tcrbert.model.BertTCREpitopeModel.PredictionEvaluator object at 0x7ff2d7c6cb80>\n",
      "2023-11-22 17:37:39 [INFO]: n_epochs: 2\n",
      "2023-11-22 17:37:39 [INFO]: train.batch_size: 256\n",
      "2023-11-22 17:37:39 [INFO]: test.batch_size: 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training in epoch 0/2: 100%|██████████| 79/79 [00:56<00:00,  1.39batch/s]\n",
      "Validating in epoch 0/2: 100%|██████████| 20/20 [00:11<00:00,  1.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-22 17:38:47 [INFO]: [EvalScoreRecoder]: In epoch 0/2, loss train score: 0.5022270385223099, val score: 0.45719517320394515\n",
      "2023-11-22 17:38:47 [INFO]: [EvalScoreRecoder]: In epoch 0/2, accuracy train score: 0.7348854798092351, val score: 0.7677877286585366\n",
      "2023-11-22 17:38:47 [INFO]: [EarlyStopper]: In epoch 0/2, accuracy score: 0.7677877286585366, best accuracy score: -inf;update best score to 0.7677877286585366\n",
      "2023-11-22 17:38:47 [INFO]: [ModelCheckpoint]: Checkpoint at epoch 0: accuracy improved from -inf to 0.7677877286585366, saving model to ../output/testexp/train.1.model_0.chk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training in epoch 1/2: 100%|██████████| 79/79 [00:55<00:00,  1.42batch/s]\n",
      "Validating in epoch 1/2: 100%|██████████| 20/20 [00:11<00:00,  1.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-22 17:39:54 [INFO]: [EvalScoreRecoder]: In epoch 1/2, loss train score: 0.4050456447691857, val score: 0.4712764069437981\n",
      "2023-11-22 17:39:54 [INFO]: [EvalScoreRecoder]: In epoch 1/2, accuracy train score: 0.8037354864949189, val score: 0.774780868902439\n",
      "2023-11-22 17:39:54 [INFO]: [EarlyStopper]: In epoch 1/2, accuracy score: 0.774780868902439, best accuracy score: 0.7677877286585366;update best score to 0.774780868902439\n",
      "2023-11-22 17:39:54 [INFO]: [ModelCheckpoint]: Checkpoint at epoch 1: accuracy improved from 0.7677877286585366 to 0.774780868902439, saving model to ../output/testexp/train.1.model_1.chk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-22 17:39:54 [INFO]: [EvalScoreRecoder]: loss train socres: [0.5022270385223099, 0.4050456447691857], val scores: [0.45719517320394515, 0.4712764069437981]\n",
      "2023-11-22 17:39:54 [INFO]: [EvalScoreRecoder]: accuracy train socres: [0.7348854798092351, 0.8037354864949189], val scores: [0.7677877286585366, 0.774780868902439]\n",
      "2023-11-22 17:39:54 [INFO]: End training...\n",
      "2023-11-22 17:39:54 [INFO]: ======================\n",
      "2023-11-22 17:39:54 [INFO]: 1 train round result: {'metrics': ['accuracy'], 'train.score': OrderedDict([('loss', [0.5022270385223099, 0.4050456447691857]), ('accuracy', [0.7348854798092351, 0.8037354864949189])]), 'val.score': OrderedDict([('loss', [0.45719517320394515, 0.4712764069437981]), ('accuracy', [0.7677877286585366, 0.774780868902439])]), 'n_epochs': 2, 'stopped_epoch': 1, 'monitor': 'accuracy', 'best_epoch': 1, 'best_score': 0.774780868902439, 'best_chk': '../output/testexp/train.1.model_1.chk'}, writing to ../output/testexp/train.1.result.json\n",
      "2023-11-22 17:39:54 [INFO]: End of 1 train round.\n",
      "2023-11-22 17:39:54 [INFO]: End of 2 train rounds of testexp, collapsed: 0:04:39.612146\n",
      "2023-11-22 17:39:54 [INFO]: ======================\n",
      "2023-11-22 17:39:54 [INFO]: Backup train results to ../output/testexp/train.bak.202311221739.tar.gz\n",
      "2023-11-22 17:39:54 [INFO]: Adding ../output/testexp/train.0.result.json to ../output/testexp/train.bak.202311221739.tar.gz\n",
      "2023-11-22 17:39:54 [INFO]: Adding ../output/testexp/train.0.model_1.chk to ../output/testexp/train.bak.202311221739.tar.gz\n",
      "2023-11-22 17:40:19 [INFO]: Adding ../output/testexp/train.1.result.json to ../output/testexp/train.bak.202311221739.tar.gz\n",
      "2023-11-22 17:40:19 [INFO]: Adding ../output/testexp/train.1.model_1.chk to ../output/testexp/train.bak.202311221739.tar.gz\n",
      "2023-11-22 17:40:44 [INFO]: Done to backup train results to ../output/testexp/train.bak.202311221739.tar.gz\n",
      "2023-11-22 17:40:44 [INFO]: Create TAPE model using config: ../config/bert-base/\n",
      "2023-11-22 17:40:44 [INFO]: Loading the eval model from ../output/testexp/train.1.model_1.chk\n",
      "2023-11-22 17:40:45 [INFO]: Predicting for shomuradova\n",
      "2023-11-22 17:40:45 [INFO]: ======================\n",
      "2023-11-22 17:40:45 [INFO]: Begin predict...\n",
      "2023-11-22 17:40:45 [INFO]: use_cuda, device: True, cuda:0\n",
      "2023-11-22 17:40:45 [INFO]: n_data: 610\n",
      "2023-11-22 17:40:45 [INFO]: batch_size: 610\n",
      "2023-11-22 17:40:45 [INFO]: [PredResultRecoder]: on_predict_begin...\n",
      "2023-11-22 17:40:45 [INFO]: Begin 0/1 prediction batch\n",
      "2023-11-22 17:40:46 [INFO]: End 0/1 prediction batch\n",
      "2023-11-22 17:40:46 [INFO]: [PredResultRecoder]: on_predict_end...\n",
      "2023-11-22 17:40:46 [INFO]: Done to predict...\n",
      "2023-11-22 17:40:46 [INFO]: ======================\n"
     ]
    }
   ],
   "source": [
    "from tcrbert.dataset import TCREpitopeSentenceDataset, CN\n",
    "from collections import OrderedDict, Counter\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "eval_ds = TCREpitopeSentenceDataset.from_key('shomuradova')\n",
    "\n",
    "metrics = ['accuracy', 'f1', 'roc_auc']\n",
    "\n",
    "# Train\n",
    "experiment.train()\n",
    "\n",
    "# Backup the train results\n",
    "experiment.backup_train_results()\n",
    "\n",
    "# Get best model and evaluate the model\n",
    "model = experiment.load_eval_model()\n",
    "eval_recoder = PredResultRecoder(output_attentions=True, output_hidden_states=True)\n",
    "model.add_pred_listener(eval_recoder)    \n",
    "data_loader = DataLoader(eval_ds, batch_size=len(eval_ds), shuffle=False, num_workers=2)\n",
    "logger.info('Predicting for %s' % eval_ds.name)\n",
    "model.predict(data_loader=data_loader, metrics=metrics, use_cuda=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "639px",
    "left": "1740px",
    "right": "20px",
    "top": "120px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
